本文件夹包含了项目中用于音频处理、视频处理和机器学习任务的核心Python脚本，执行后会压缩封存，该代码对GPU要求极高，需要运行在云平台。

 melspectrogram.py——
音频处理和特征提取脚本，
主要功能：
- 加载WAV音频文件
- 生成梅尔频谱图
- 保存频谱图数据（.npy格式）和可视化图像（.png格式）

gpu_paddleocr_opencv.py——
用于视频处理和字幕提取，
主要功能：
使用OpenCV读取视频帧
使用paddleocr进行OCR字幕识别
生成.ass格式的字幕文件

kmeans.py——
主要功能：音频聚类（用于角色分类）

emotion_tagging.py——
主要功能：情感标注，利用大模型自动实现， 比较粗糙，但本项目不需要过于精细的标注。
代码简述：
使用 Hugging Face 的 transformers 库加载预训练的 RoBERTa 模型（roberta-base），该模型用于情感分类，包含四个情感类别：Happy（高兴）、Sad（悲伤）、Angry（愤怒）、Neutral（中性）。自动检测是否有可用的 GPU，并将模型和数据加载到 GPU 上加速处理。
情感分类：
局部情感分类：逐条对字幕文本进行情感分类，输出每条字幕的情感类别。
全局情感分类：将每三个字幕文本作为一个时间窗口，拼接为一个整体，并对其进行全局情感标注。生成的全局情感标注会应用到窗口中的每一条字幕。
时间处理：
该项目中的 ASS 文件字幕时间戳精确到毫秒，因此在解析时间戳时，代码保留了秒和毫秒的精度，并将其转换为以秒为单位的时间。
数据处理与 JSON 生成：
每个字幕文件中的对话都会按顺序读取，并将三条字幕组成一个时间窗口。局部和全局情感标注结果将以 JSON 格式保存，包含以下字段：
text_original：原始字幕文本。
start_time：字幕的开始时间（以秒为单位）。
end_time：字幕的结束时间（以秒为单位）。
emotion_category：局部情感标注结果。
global_emotion：全局情感标注结果（对三条字幕共享一个全局情感标注）。
存储结果：
处理完所有的字幕文件后，项目将情感标注结果保存为一个名为 output.json 的文件。
使用说明
ASS 文件：将待处理的 ASS 文件放入 ass_file_set 文件夹。
运行项目：直接运行项目的主文件，该程序会自动读取 ass_file_set 文件夹中的所有 ASS 文件，并进行情感分类和标注。
输出文件：情感标注结果将以 JSON 格式保存至项目根目录中的 output.json 文件。

------------------------------------------------------------------------------------
优化方向
优化音频聚类算法，提高角色分类的准确性
探索更高效的字幕提取方法，可能需要针对动漫视频进行特殊优化

下一步计划
整合这些脚本到一个统一的数据处理流程中
实现数据增强技术，提高模型鲁棒性
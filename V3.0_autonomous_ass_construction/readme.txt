## 多模态台词情感分析模型

### 概述
通过分析视频中的音频和台词字幕，实现多模态情感分类。项目涉及视频处理、音频分析、光学字符识别（OCR）及深度学习模型的构建。

### 数据预处理

#### 视频数据
- **格式**: `.flv`
- **数量**: 14 个视频文件
- **单个视频大小**: 约 1GB
- **单个视频时长**: 约 24 分钟

#### 音频处理
1. **处理流程**:
   - **格式转换**: 将视频中的音频提取为 WAV 格式（`extract_wav.py`）
   - **音频清洗**: 使用高通滤波处理音频（`audio_filter.py`）
   - **生成梅尔频谱图**: 使用 `librosa` 库生成梅尔频谱图（`librosa.py`）
   - **聚类分析**: 利用 `kMeans` 聚类分析（`kmeans.py`）
   - **存储格式**: 结果以 `.npy` 格式保存

2. **设计原因**:
   - 保留 WAV 文件，为后续实验提供灵活性
   - 梅尔频谱图用于降维和特征提取
   - `.npy` 格式便于深度学习模型读取

#### 字幕提取（'gpu_paddleorc_opencv.py'）
1. **工具使用**:
   - **视频帧提取**: OpenCV
   - **文字识别**: PaddleOCR

2. **处理细节**:
   - **抽帧频率**: 每秒 10 帧
   - **时间精度**: 10ms
   - **输出格式**: `.ass` 字幕文件

3. **优化方向**:
   - 引入多线程提升处理效率
   - 采用图像预处理提升 OCR 准确率

#### json生成（'construct_audio_json.py'或'construct_spectrogram_json.py'）
 1. **第一个wav作为输入**:

 2. **第二个频谱图作为输入**:

### 模型构建

#### 模型架构
1. **结构概述**: 多模态模型，结合音频和文本特征。
2. **音频处理**: 使用卷积神经网络（CNN）处理梅尔频谱图。
3. **文本处理**: 通过循环神经网络（RNN）或 Transformer 处理文本数据。
4. **时间建模**: 
   - 添加全局上下文读取层，捕捉情感趋势，帮助局部时间窗口分析。

### 环境配置

#### 软件环境
- **Python 版本**: 3.9
- **PaddleOCR 版本**: 最新
- **OpenCV 版本**: 最新
- **其他依赖项**: 
  - opencv-contrib-python
  - paddleocr
  - paddlepaddle-gpu
  - numpy
  - scipy
  - difflib
  - re

#### 硬件环境
- **GPU**: NVIDIA GeForce RTX 4090 D (24 GB 显存)
- **CUDA 版本**: 12.4
- **CPU**: AMD EPYC 9754 128-Core Processor (128 核，256 线程，最大频率 3.1 GHz)

#### 操作系统
- **OS**: Ubuntu 22.04

### 训练策略

1. **两阶段训练**:
   - **第一阶段**: 基于全局对话上下文进行预训练
   - **第二阶段**: 通过更细分的时间窗口微调模型

2. **时间窗口选择**:
   - 根据对话连续性与上下文关系确定最佳窗口，避免不相关的对话干扰。

### 待解决问题与优化方向

1. **时间窗口优化**: 需要进一步实验，确定最佳时间窗口大小。
2. **字幕提取率提升**: 目前字幕提取率约为 50%-60%，未来可能优化 `ass` 制作脚本以提高准确率。

### 注意事项
- **Docker 封装**: 依赖项较多，建议使用 Docker 进行环境封装。